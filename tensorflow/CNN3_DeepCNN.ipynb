{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Learning started.\n",
      "Epoch: 01 loss =  0.425422086\n",
      "Epoch: 02 loss =  0.087821482\n",
      "Epoch: 03 loss =  0.066076504\n",
      "Epoch: 04 loss =  0.058528571\n",
      "Epoch: 05 loss =  0.049762842\n",
      "Epoch: 06 loss =  0.044508421\n",
      "Epoch: 07 loss =  0.042546945\n",
      "Epoch: 08 loss =  0.037399174\n",
      "Epoch: 09 loss =  0.037450111\n",
      "Epoch: 10 loss =  0.035940507\n",
      "Epoch: 11 loss =  0.032866878\n",
      "Epoch: 12 loss =  0.032856472\n",
      "Epoch: 13 loss =  0.032372867\n",
      "Epoch: 14 loss =  0.029104353\n",
      "Epoch: 15 loss =  0.028456662\n",
      "Learning ended.\n",
      "Accuracy: 0.9943\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6049823e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28*28])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME')\n",
    "L1_relu = tf.nn.relu(L1)\n",
    "L1_maxpool = tf.nn.max_pool(L1_relu, ksize=[1,2,2,1],\n",
    "                           strides=[1,2,2,1], padding='SAME')\n",
    "L1_dp = tf.nn.dropout(L1_maxpool, keep_prob)\n",
    "print(L1)\n",
    "print(L1_relu)\n",
    "print(L1_maxpool)\n",
    "print(L1_dp)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1_dp, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2_relu = tf.nn.relu(L2)\n",
    "L2_maxpool = tf.nn.max_pool(L2_relu, ksize=[1,2,2,1],\n",
    "                           strides=[1,2,2,1], padding='SAME')\n",
    "L2_dp = tf.nn.dropout(L2_maxpool, keep_prob)\n",
    "print(L2)\n",
    "print(L2_relu)\n",
    "print(L2_maxpool)\n",
    "print(L2_dp)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2_dp, W3, strides=[1,1,1,1], padding='SAME')\n",
    "L3_relu = tf.nn.relu(L3)\n",
    "L3_maxpool = tf.nn.max_pool(L3_relu, ksize=[1,2,2,1],\n",
    "                           strides=[1,2,2,1], padding='SAME')\n",
    "L3_dp = tf.nn.dropout(L3_maxpool, keep_prob)\n",
    "print(L3)\n",
    "print(L3_relu)\n",
    "print(L3_maxpool)\n",
    "print(L3_dp)\n",
    "\n",
    "L3_flat = tf.reshape(L3_dp, [-1, 4*4*128])\n",
    "\n",
    "W4 = tf.get_variable('W4', shape = [4*4*128, 256],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([256]))\n",
    "L4 = tf.matmul(L3_flat, W4) + b4\n",
    "\n",
    "W5 = tf.get_variable('W5', shape = [256, 10],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Learning started.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        x, y = mnist.train.next_batch(batch_size)\n",
    "        feed = {X: x, Y:y, keep_prob: 0.7}\n",
    "        _, l = sess.run([optimizer, loss], feed)\n",
    "        avg_loss += l/total_batch\n",
    "    print('Epoch:', '%02d'%(epoch+1), 'loss = ', '{:.9f}'.format(avg_loss))\n",
    "print('Learning ended.')\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, {X:mnist.test.images, Y:mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(logits, 1), {X:mnist.test.images[r:r+1], keep_prob: 1}))\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28),\n",
    "          cmap = 'Greys', interpolation = 'nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
